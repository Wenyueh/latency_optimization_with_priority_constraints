# change of latency for predictor

python main.py  --priority_predictor_latency 0.001 --length_predictor_latency 0.001 --priority_predictor_batching_size 4 --length_predictor_batching_size 4 --processing_mode fully_delayed_processing --max_concurrent_user_requests 4 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.001 --length_predictor_latency 0.001 --priority_predictor_batching_size 4 --length_predictor_batching_size 4 --processing_mode immediate_processing --max_concurrent_user_requests 4 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.001 --length_predictor_latency 0.001 --priority_predictor_batching_size 16 --length_predictor_batching_size 16 --processing_mode fully_delayed_processing --max_concurrent_user_requests 4 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.001 --length_predictor_latency 0.001 --priority_predictor_batching_size 16 --length_predictor_batching_size 16 --processing_mode immediate_processing --max_concurrent_user_requests 4 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.001 --length_predictor_latency 0.001 --priority_predictor_batching_size 32 --length_predictor_batching_size 32 --processing_mode fully_delayed_processing --max_concurrent_user_requests 4 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.001 --length_predictor_latency 0.001 --priority_predictor_batching_size 32 --length_predictor_batching_size 32 --processing_mode immediate_processing --max_concurrent_user_requests 4 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.001 --length_predictor_latency 0.001 --priority_predictor_batching_size 64 --length_predictor_batching_size 64 --processing_mode fully_delayed_processing --max_concurrent_user_requests 4 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.001 --length_predictor_latency 0.001 --priority_predictor_batching_size 64 --length_predictor_batching_size 64 --processing_mode immediate_processing --max_concurrent_user_requests 4 --experiment_name "latency"


python main.py  --priority_predictor_latency 0.01 --length_predictor_latency 0.01 --priority_predictor_batching_size 4 --length_predictor_batching_size 4 --processing_mode fully_delayed_processing --max_concurrent_user_requests 16 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.01 --length_predictor_latency 0.01 --priority_predictor_batching_size 4 --length_predictor_batching_size 4 --processing_mode immediate_processing --max_concurrent_user_requests 16 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.01 --length_predictor_latency 0.01 --priority_predictor_batching_size 16 --length_predictor_batching_size 16 --processing_mode fully_delayed_processing --max_concurrent_user_requests 16 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.01 --length_predictor_latency 0.01 --priority_predictor_batching_size 16 --length_predictor_batching_size 16 --processing_mode immediate_processing --max_concurrent_user_requests 16 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.01 --length_predictor_latency 0.01 --priority_predictor_batching_size 32 --length_predictor_batching_size 32 --processing_mode fully_delayed_processing --max_concurrent_user_requests 16 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.01 --length_predictor_latency 0.01 --priority_predictor_batching_size 32 --length_predictor_batching_size 32 --processing_mode immediate_processing --max_concurrent_user_requests 16 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.01 --length_predictor_latency 0.01 --priority_predictor_batching_size 64 --length_predictor_batching_size 64 --processing_mode fully_delayed_processing --max_concurrent_user_requests 16 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.01 --length_predictor_latency 0.01 --priority_predictor_batching_size 64 --length_predictor_batching_size 64 --processing_mode immediate_processing --max_concurrent_user_requests 16 --experiment_name "latency"


python main.py  --priority_predictor_latency 0.1 --length_predictor_latency 0.1 --priority_predictor_batching_size 4 --length_predictor_batching_size 4 --processing_mode fully_delayed_processing --max_concurrent_user_requests 32 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.1 --length_predictor_latency 0.1 --priority_predictor_batching_size 4 --length_predictor_batching_size 4 --processing_mode immediate_processing --max_concurrent_user_requests 32 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.1 --length_predictor_latency 0.1 --priority_predictor_batching_size 16 --length_predictor_batching_size 16 --processing_mode fully_delayed_processing --max_concurrent_user_requests 32 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.1 --length_predictor_latency 0.1 --priority_predictor_batching_size 16 --length_predictor_batching_size 16 --processing_mode immediate_processing --max_concurrent_user_requests 32 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.1 --length_predictor_latency 0.1 --priority_predictor_batching_size 32 --length_predictor_batching_size 32 --processing_mode fully_delayed_processing --max_concurrent_user_requests 32 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.1 --length_predictor_latency 0.1 --priority_predictor_batching_size 32 --length_predictor_batching_size 32 --processing_mode immediate_processing --max_concurrent_user_requests 32 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.1 --length_predictor_latency 0.1 --priority_predictor_batching_size 64 --length_predictor_batching_size 64 --processing_mode fully_delayed_processing --max_concurrent_user_requests 32 --experiment_name "latency"

python main.py  --priority_predictor_latency 0.1 --length_predictor_latency 0.1 --priority_predictor_batching_size 64 --length_predictor_batching_size 64 --processing_mode immediate_processing --max_concurrent_user_requests 32 --experiment_name "latency"



python main.py  --priority_predictor_latency 1 --length_predictor_latency 1 --priority_predictor_batching_size 4 --length_predictor_batching_size 4 --processing_mode fully_delayed_processing --max_concurrent_user_requests 64 --experiment_name "latency"

python main.py  --priority_predictor_latency 1 --length_predictor_latency 1 --priority_predictor_batching_size 4 --length_predictor_batching_size 4 --processing_mode immediate_processing --max_concurrent_user_requests 64 --experiment_name "latency"

python main.py  --priority_predictor_latency 1 --length_predictor_latency 1 --priority_predictor_batching_size 16 --length_predictor_batching_size 16 --processing_mode fully_delayed_processing --max_concurrent_user_requests 64 --experiment_name "latency"

python main.py  --priority_predictor_latency 1 --length_predictor_latency 1 --priority_predictor_batching_size 16 --length_predictor_batching_size 16 --processing_mode immediate_processing --max_concurrent_user_requests 64 --experiment_name "latency"

python main.py  --priority_predictor_latency 1 --length_predictor_latency 1 --priority_predictor_batching_size 32 --length_predictor_batching_size 32 --processing_mode fully_delayed_processing --max_concurrent_user_requests 64 --experiment_name "latency"

python main.py  --priority_predictor_latency 1 --length_predictor_latency 1 --priority_predictor_batching_size 32 --length_predictor_batching_size 32 --processing_mode immediate_processing --max_concurrent_user_requests 64 --experiment_name "latency"

python main.py  --priority_predictor_latency 1 --length_predictor_latency 1 --priority_predictor_batching_size 64 --length_predictor_batching_size 64 --processing_mode fully_delayed_processing --max_concurrent_user_requests 64 --experiment_name "latency"

python main.py  --priority_predictor_latency 1 --length_predictor_latency 1 --priority_predictor_batching_size 64 --length_predictor_batching_size 64 --processing_mode immediate_processing --max_concurrent_user_requests 64 --experiment_name "latency"
